
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<title>Predicting Customer Churn: A CRISP-DM Case Study with RFM, Behavioral Signals, and Interpretable Models</title>
<style>
 body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
        line-height: 1.5; max-width: 920px; margin: 2rem auto; padding: 0 1rem; color: #111; }
 h1, h2, h3 { line-height: 1.25; }
 h1 { font-size: 1.9rem; margin-bottom: 0.2rem; }
 h2 { font-size: 1.35rem; margin-top: 2rem; }
 h3 { font-size: 1.1rem; margin-top: 1.2rem; }
 .meta { color: #555; margin-bottom: 1.2rem; }
 code, pre { background: #f6f8fa; }
 .box { background:#fafafa; border:1px solid #eee; padding: 0.9rem; }
 ul { margin-top:0.2rem; }
 figure { margin: 1rem 0; }
 table { border-collapse: collapse; width: 100%; }
 th, td { border:1px solid #ddd; padding:6px 8px; }
 th { background:#fafafa; }
 .small { font-size: 0.92em; color: #444; }
</style>
</head>
<body>

<h1>Predicting Customer Churn: A CRISP-DM Case Study with RFM, Behavioral Signals, and Interpretable Models</h1>
<div class="meta">Authors: Data Science Team (You) · Technical Partner: GPT‑5 Thinking</div>

<h2>Abstract</h2>
<p>We present an end-to-end churn prediction project aligned to CRISP-DM. Using a labeled customer dataset with behavioral,
billing, and support signals, we (i) conducted structured EDA, (ii) built RFM scores to interpret recency–frequency–monetary
patterns, (iii) engineered friction and interaction features, (iv) explored unsupervised segments, and (v) trained
compute-aware supervised models. A regularized logistic regression delivered strong discrimination
(ROC–AUC ≈ 0.959 and PR–AUC ≈ 0.974 on a 3-fold CV sample), while RFM segments and friction signals
provided clear retention levers (support calls ↑, payment delays ↑, and stale recency ↑ are most predictive of churn).
We conclude with a cost-aware retention strategy and deployment guidance.</p>

<h2>1. Business Understanding</h2>
<div class="box small">
  <b>Objective:</b> Predict churn to drive proactive retention. <b>Why it matters:</b> acquiring a new customer is typically 5–25× costlier than retaining an existing one; timely interventions can improve net revenue and reduce support load.<br/>
  <b>Success criteria:</b> high PR-AUC and recall for churners, precision tuned to retention budget; clear, actionable drivers (support calls, delays, recency) to inform policies.
</div>

<h2>2. Data</h2>
<p>Training data with demographics, tenure, usage, support calls, payment delay, subscription type, contract length, total spend, last interaction, and churn label. A separate test file (64,374 rows) is reserved for final generalization.</p>

<h2>3. Methods</h2>
<h3>3.1 EDA & RFM</h3>
<ul>
  <li>Explored distributions and missingness; class balance confirmed in sample.</li>
  <li>Built <b>RFM</b>: R (recency ↑ = more recent), F (0.7×usage + 0.3×few-calls), M (total spend).</li>
  <li>Segment taxonomy: Champions, Loyal/Recent, Potential Loyalist, High-Value At-Risk, At Risk, Hibernating, New but Inactive, Need Attention.</li>
</ul>


<h3>3.2 Feature Engineering</h3>
<ul>
  <li>Friction: <code>SupportCalls</code>, <code>PaymentDelay</code>, <code>DelayRatio30</code></li>
  <li>Interactions: <code>CallsXDelay</code>, <code>UsageXTenure</code>, <code>RecencyXCalls</code></li>
  <li>Monetary normalization: <code>SpendPerTenure</code></li>
  <li>Plus RFM scores (R,F,M, 1–5)</li>
</ul>



<h3>3.3 Unsupervised Exploration</h3>
<p>MiniBatch K-Means on RFM + friction/engagement (impute + RobustScaler). Picked k by silhouette on a tiny sample, then profiled clusters by churn rate and size.</p>


<h3>3.4 Supervised Modeling</h3>
<p>Common preprocessing in a sklearn <i>ColumnTransformer</i>; 3-fold stratified CV; models: Majority baseline, Logistic (L2, balanced). Tree/Boosting variants are planned next using the same protocol.</p>

    <figure>
      <img src="fig_model_roc.png" alt="Model comparison — ROC-AUC (3-fold CV)." style="max-width:100%;height:auto;border:1px solid #ddd;padding:4px;">
      <figcaption style="font-size:0.9em;color:#555;">Model comparison — ROC-AUC (3-fold CV).</figcaption>
    </figure>
    

    <figure>
      <img src="fig_model_pr.png" alt="Model comparison — PR-AUC (3-fold CV)." style="max-width:100%;height:auto;border:1px solid #ddd;padding:4px;">
      <figcaption style="font-size:0.9em;color:#555;">Model comparison — PR-AUC (3-fold CV).</figcaption>
    </figure>
    

<h2>4. Results</h2>
<ul>
  <li><b>Predictive strength:</b> Logistic regression achieved ROC–AUC ≈ <b>0.959</b>, PR–AUC ≈ <b>0.974</b> on the 10k CV sample.</li>
  <li><b>Drivers:</b> churn risk increases with <b>more support calls</b> and <b>higher payment delays</b>, and decreases with <b>recent interactions</b> and <b>higher spend/engagement</b>.</li>
  <li><b>Segments:</b> “At Risk” and “Hibernating” show the highest churn; “High-Value At-Risk” has smaller volume but demands white‑glove action.</li>
</ul>

<h2>5. Recommendations</h2>
<ol>
  <li><b>Targeted retention playbooks</b><br/>
      • <i>High-Value At-Risk</i>: agent-led outreach; fix billing friction; personalized credits.<br/>
      • <i>At Risk/Hibernating</i>: low-cost bulk nudges; reactivation campaigns; clear “first-success” paths.<br/>
      • <i>New but Inactive</i>: onboarding prompts; usage milestones; concierge tips in week 1–4.</li>
  <li><b>Operational thresholds</b><br/>
      Calibrate the probability threshold using PR curves vs. retention budget (optimize expected net revenue). Maintain two thresholds: 
      <i>high‑touch</i> (small, top‑risk list) and <i>low‑touch</i> (broader, cheap channels).</li>
  <li><b>Friction reduction</b><br/>
      Monitor <i>support calls</i> & <i>payment delays</i> weekly by segment; trigger proactive outreach when either spikes.</li>
  <li><b>Safeguards</b><br/>
      Fairness check on demographic fields; prefer behavior/usage features for decisions.</li>
</ol>

<h2>6. Deployment & Monitoring</h2>
<ul>
  <li><b>Pipeline</b>: nightly training job → probability scores → prioritized retention queues.</li>
  <li><b>Dashboards</b>: segment churn, precision/recall at operating threshold, outreach lift A/B.</li>
  <li><b>Drift detection</b>: monitor feature distributions & calibration; retrain on schedule or when drift alarms trigger.</li>
</ul>

<h2>7. Limitations & Next Work</h2>
<ul>
  <li>We used a compute-lean CV sample for speed; confirm results on the full training set.</li>
  <li>Add tree/boosting models (Random Forest, Gradient Boosting) for non-linear effects.</li>
  <li>Produce <b>test-set predictions</b> (64,374 rows) and a ranked retention list with action tags.</li>
  <li>Run SHAP for global/local explanations and error analysis on false positives/negatives.</li>
</ul>

<h2>8. Reproducibility & Artifacts</h2>
<p>All intermediate tables and figures are saved. Download individually below or grab the ZIP bundle.</p>
<ul>
  <li>Model CV results (Part 1) — <a href="/mnt/data/model_cv_results_part1.csv">model_cv_results_part1.csv</a></li><li>Detailed RFM PDF — <a href="/mnt/data/Churn_RFM_Detailed_Report.pdf">Churn_RFM_Detailed_Report.pdf</a></li><li>RFM segment statistics (CSV) — <a href="/mnt/data/RFM_SEGMENT_STATS_DETAILED.csv">RFM_SEGMENT_STATS_DETAILED.csv</a></li><li>Churn by R quintile (CSV) — <a href="/mnt/data/RFM_churn_by_R_quintile.csv">RFM_churn_by_R_quintile.csv</a></li><li>Churn by F quintile (CSV) — <a href="/mnt/data/RFM_churn_by_F_quintile.csv">RFM_churn_by_F_quintile.csv</a></li><li>Churn by M quintile (CSV) — <a href="/mnt/data/RFM_churn_by_M_quintile.csv">RFM_churn_by_M_quintile.csv</a></li><li>R×F churn heatmap (CSV) — <a href="/mnt/data/RFM_heatmap_RxF.csv">RFM_heatmap_RxF.csv</a></li>
</ul>

<div class="box small">
<strong>Bundle (ZIP):</strong> Once you download the ZIP, extract it to see the HTML report, figures, and CSVs in one folder.
</div>

<hr/>
<p class="small">Prepared in a CRISP‑DM flow: Business Understanding → Data Understanding (EDA & RFM) → Data Prep → Feature Engineering → Unsupervised Segmentation → Modeling → Recommendations and Deployment.</p>

</body>
</html>
